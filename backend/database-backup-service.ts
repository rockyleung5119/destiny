// Cloudflare D1æ•°æ®åº“è‡ªåŠ¨å¤‡ä»½æœåŠ¡
// æ¯å¤©è‡ªåŠ¨å¤‡ä»½D1æ•°æ®åº“åˆ°R2å­˜å‚¨

interface Env {
  DB: D1Database;
  BACKUP_STORAGE: R2Bucket;
  BACKUP_NOTIFICATION_EMAIL?: string;
}

export class DatabaseBackupService {
  private env: Env;
  
  constructor(env: Env) {
    this.env = env;
  }

  /**
   * æ‰§è¡Œæ•°æ®åº“å¤‡ä»½
   */
  async performBackup(): Promise<{ success: boolean; message: string; backupInfo?: any }> {
    try {
      console.log('ğŸ”„ Starting database backup process...');
      
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const backupFileName = `destiny-db-backup-${timestamp}.sql`;
      
      // 1. è·å–æ‰€æœ‰è¡¨çš„ç»“æ„å’Œæ•°æ®
      const backupData = await this.generateBackupSQL();
      
      // 2. å‹ç¼©å¤‡ä»½æ•°æ®ï¼ˆå¯é€‰ï¼‰
      const compressedData = await this.compressData(backupData);
      
      // 3. ä¸Šä¼ åˆ°R2å­˜å‚¨
      const uploadResult = await this.uploadToR2(backupFileName, compressedData);
      
      // 4. æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
      await this.cleanupOldBackups();
      
      // 5. è®°å½•å¤‡ä»½ä¿¡æ¯
      const backupInfo = {
        fileName: backupFileName,
        timestamp: new Date().toISOString(),
        size: compressedData.length,
        tables: await this.getTableList(),
        success: true
      };
      
      console.log('âœ… Database backup completed successfully:', backupInfo);
      
      return {
        success: true,
        message: `Database backup completed: ${backupFileName}`,
        backupInfo
      };
      
    } catch (error) {
      console.error('âŒ Database backup failed:', error);
      
      return {
        success: false,
        message: `Database backup failed: ${error.message}`
      };
    }
  }

  /**
   * ç”Ÿæˆå®Œæ•´çš„SQLå¤‡ä»½
   */
  private async generateBackupSQL(): Promise<string> {
    let sqlBackup = '';
    
    // æ·»åŠ å¤‡ä»½å¤´ä¿¡æ¯
    sqlBackup += `-- Destiny Database Backup\n`;
    sqlBackup += `-- Generated: ${new Date().toISOString()}\n`;
    sqlBackup += `-- Database: destiny-db\n\n`;
    
    // è·å–æ‰€æœ‰è¡¨
    const tables = await this.getTableList();
    
    for (const tableName of tables) {
      console.log(`ğŸ“Š Backing up table: ${tableName}`);
      
      // è·å–è¡¨ç»“æ„
      const schema = await this.getTableSchema(tableName);
      sqlBackup += `-- Table: ${tableName}\n`;
      sqlBackup += `${schema}\n\n`;
      
      // è·å–è¡¨æ•°æ®
      const data = await this.getTableData(tableName);
      if (data.length > 0) {
        sqlBackup += `-- Data for table: ${tableName}\n`;
        for (const row of data) {
          const insertSQL = this.generateInsertSQL(tableName, row);
          sqlBackup += `${insertSQL}\n`;
        }
        sqlBackup += `\n`;
      }
    }
    
    return sqlBackup;
  }

  /**
   * è·å–æ‰€æœ‰è¡¨å
   */
  private async getTableList(): Promise<string[]> {
    try {
      const result = await this.env.DB.prepare(`
        SELECT name FROM sqlite_master 
        WHERE type='table' AND name NOT LIKE 'sqlite_%'
        ORDER BY name
      `).all();
      
      return result.results.map((row: any) => row.name);
    } catch (error) {
      console.error('Failed to get table list:', error);
      return [];
    }
  }

  /**
   * è·å–è¡¨ç»“æ„
   */
  private async getTableSchema(tableName: string): Promise<string> {
    try {
      const result = await this.env.DB.prepare(`
        SELECT sql FROM sqlite_master 
        WHERE type='table' AND name=?
      `).bind(tableName).first();
      
      return result?.sql || '';
    } catch (error) {
      console.error(`Failed to get schema for table ${tableName}:`, error);
      return '';
    }
  }

  /**
   * è·å–è¡¨æ•°æ®
   */
  private async getTableData(tableName: string): Promise<any[]> {
    try {
      const result = await this.env.DB.prepare(`SELECT * FROM ${tableName}`).all();
      return result.results || [];
    } catch (error) {
      console.error(`Failed to get data for table ${tableName}:`, error);
      return [];
    }
  }

  /**
   * ç”ŸæˆINSERT SQLè¯­å¥
   */
  private generateInsertSQL(tableName: string, row: any): string {
    const columns = Object.keys(row);
    const values = columns.map(col => {
      const value = row[col];
      if (value === null) return 'NULL';
      if (typeof value === 'string') return `'${value.replace(/'/g, "''")}'`;
      return value;
    });
    
    return `INSERT INTO ${tableName} (${columns.join(', ')}) VALUES (${values.join(', ')});`;
  }

  /**
   * å‹ç¼©æ•°æ®ï¼ˆç®€å•çš„gzipå‹ç¼©ï¼‰
   */
  private async compressData(data: string): Promise<Uint8Array> {
    // åœ¨Cloudflare Workersä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨CompressionStream
    const stream = new CompressionStream('gzip');
    const writer = stream.writable.getWriter();
    const reader = stream.readable.getReader();
    
    // å†™å…¥æ•°æ®
    await writer.write(new TextEncoder().encode(data));
    await writer.close();
    
    // è¯»å–å‹ç¼©åçš„æ•°æ®
    const chunks: Uint8Array[] = [];
    let done = false;
    
    while (!done) {
      const { value, done: readerDone } = await reader.read();
      done = readerDone;
      if (value) {
        chunks.push(value);
      }
    }
    
    // åˆå¹¶æ‰€æœ‰chunks
    const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
    const result = new Uint8Array(totalLength);
    let offset = 0;
    
    for (const chunk of chunks) {
      result.set(chunk, offset);
      offset += chunk.length;
    }
    
    return result;
  }

  /**
   * ä¸Šä¼ åˆ°R2å­˜å‚¨
   */
  private async uploadToR2(fileName: string, data: Uint8Array): Promise<boolean> {
    try {
      console.log(`ğŸ“¤ Uploading backup to R2: ${fileName}`);
      
      await this.env.BACKUP_STORAGE.put(fileName, data, {
        httpMetadata: {
          contentType: 'application/gzip',
          contentEncoding: 'gzip'
        },
        customMetadata: {
          backupDate: new Date().toISOString(),
          database: 'destiny-db',
          type: 'full-backup'
        }
      });
      
      console.log(`âœ… Backup uploaded successfully: ${fileName}`);
      return true;
    } catch (error) {
      console.error('Failed to upload backup to R2:', error);
      throw error;
    }
  }

  /**
   * æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
   */
  private async cleanupOldBackups(): Promise<void> {
    try {
      console.log('ğŸ§¹ Cleaning up old backups...');
      
      const thirtyDaysAgo = new Date();
      thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
      
      // åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶
      const objects = await this.env.BACKUP_STORAGE.list({
        prefix: 'destiny-db-backup-'
      });
      
      let deletedCount = 0;
      
      for (const object of objects.objects) {
        // ä»æ–‡ä»¶åæå–æ—¥æœŸ
        const match = object.key.match(/destiny-db-backup-(\d{4}-\d{2}-\d{2})/);
        if (match) {
          const backupDate = new Date(match[1]);
          if (backupDate < thirtyDaysAgo) {
            await this.env.BACKUP_STORAGE.delete(object.key);
            deletedCount++;
            console.log(`ğŸ—‘ï¸ Deleted old backup: ${object.key}`);
          }
        }
      }
      
      console.log(`âœ… Cleanup completed: ${deletedCount} old backups deleted`);
    } catch (error) {
      console.error('Failed to cleanup old backups:', error);
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œæ¸…ç†å¤±è´¥ä¸åº”è¯¥å½±å“å¤‡ä»½è¿‡ç¨‹
    }
  }

  /**
   * è·å–å¤‡ä»½åˆ—è¡¨
   */
  async listBackups(): Promise<any[]> {
    try {
      const objects = await this.env.BACKUP_STORAGE.list({
        prefix: 'destiny-db-backup-'
      });
      
      return objects.objects.map(obj => ({
        fileName: obj.key,
        size: obj.size,
        uploaded: obj.uploaded,
        etag: obj.etag
      }));
    } catch (error) {
      console.error('Failed to list backups:', error);
      return [];
    }
  }

  /**
   * æ¢å¤æ•°æ®åº“ï¼ˆä»å¤‡ä»½æ–‡ä»¶ï¼‰
   */
  async restoreFromBackup(backupFileName: string): Promise<{ success: boolean; message: string }> {
    try {
      console.log(`ğŸ”„ Starting database restore from: ${backupFileName}`);
      
      // ä»R2ä¸‹è½½å¤‡ä»½æ–‡ä»¶
      const object = await this.env.BACKUP_STORAGE.get(backupFileName);
      if (!object) {
        throw new Error(`Backup file not found: ${backupFileName}`);
      }
      
      // è§£å‹æ•°æ®
      const compressedData = await object.arrayBuffer();
      const decompressedSQL = await this.decompressData(new Uint8Array(compressedData));
      
      // æ‰§è¡ŒSQLæ¢å¤
      const sqlStatements = decompressedSQL.split(';').filter(stmt => stmt.trim());
      
      for (const statement of sqlStatements) {
        if (statement.trim()) {
          await this.env.DB.prepare(statement).run();
        }
      }
      
      console.log('âœ… Database restore completed successfully');
      
      return {
        success: true,
        message: `Database restored from ${backupFileName}`
      };
      
    } catch (error) {
      console.error('âŒ Database restore failed:', error);
      
      return {
        success: false,
        message: `Database restore failed: ${error.message}`
      };
    }
  }

  /**
   * è§£å‹æ•°æ®
   */
  private async decompressData(data: Uint8Array): Promise<string> {
    const stream = new DecompressionStream('gzip');
    const writer = stream.writable.getWriter();
    const reader = stream.readable.getReader();
    
    // å†™å…¥å‹ç¼©æ•°æ®
    await writer.write(data);
    await writer.close();
    
    // è¯»å–è§£å‹åçš„æ•°æ®
    const chunks: Uint8Array[] = [];
    let done = false;
    
    while (!done) {
      const { value, done: readerDone } = await reader.read();
      done = readerDone;
      if (value) {
        chunks.push(value);
      }
    }
    
    // åˆå¹¶å¹¶è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
    const result = new Uint8Array(totalLength);
    let offset = 0;
    
    for (const chunk of chunks) {
      result.set(chunk, offset);
      offset += chunk.length;
    }
    
    return new TextDecoder().decode(result);
  }
}
